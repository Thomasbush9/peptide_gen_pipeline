#!/bin/bash
#SBATCH --job-name=boltzgen
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --gpus=1
#SBATCH --mem=64G
#SBATCH --partition=kempner_requeue
#SBATCH --account=kempner_bsabatini_lab
#SBATCH --time=03:00:00
#SBATCH --output=/n/home06/tbush/job_logs/%x.%j.out
#SBATCH --error=/n/home06/tbush/job_logs/%x.%j.err

set -euo pipefail
set -x

echo "=== SLURM INFO ==="
echo "Host:              $(hostname)"
echo "Job ID:            ${SLURM_JOB_ID:-unknown}"
echo "Node list:         ${SLURM_NODELIST:-unknown}"
echo "Submit dir:        ${SLURM_SUBMIT_DIR:-unknown}"
echo "GPUs (job):        ${SLURM_JOB_GPUS:-unknown}"
echo "CUDA_VISIBLE_DEVICES: ${CUDA_VISIBLE_DEVICES:-unset}"
echo "=================="

# Args
INPUT_FILE="${1:?Need <design_spec.yaml> as arg1}"
OUT_DIR="${2:?Need <output_dir> as arg2}"
NUM_DESIGNS="${3:?Need <num_designs> as arg3}"
shift 3

CACHE_DIR="/n/holylabs/bsabatini_lab/Lab/Boltz-project/cache_models/bg/"
JOB_OUT_DIR="${OUT_DIR}/task_${SLURM_JOB_ID}"

mkdir -p "${CACHE_DIR}" "${JOB_OUT_DIR}"

# Environment: pick ONE strategy and stick to it.
# Strategy A (recommended): keep modules minimal, just activate conda/mamba env.
module purge
module load python/3.12.8-fasrc01 gcc/14.2.0-fasrc01 cuda/12.9.1-fasrc01
mamba activate bg

echo "=== PATH / BINARIES ==="
which python
which boltzgen
python --version
echo "======================="

echo "=== NVIDIA-SMI (pre-run) ==="
nvidia-smi
echo "============================"

echo "=== TORCH CUDA INFO ==="
python - <<'PY'
import os, torch
print("torch:", torch.__version__)
print("torch.version.cuda:", torch.version.cuda)
print("cuda available:", torch.cuda.is_available())
print("device count:", torch.cuda.device_count())
if torch.cuda.is_available():
    print("current device:", torch.cuda.current_device())
    print("device name:", torch.cuda.get_device_name(0))
print("CUDA_VISIBLE_DEVICES:", os.environ.get("CUDA_VISIBLE_DEVICES"))
print("LD_LIBRARY_PATH:", os.environ.get("LD_LIBRARY_PATH",""))
PY
echo "======================="

echo "Running BoltzGen"
echo "Input:   ${INPUT_FILE}"
echo "Output:  ${JOB_OUT_DIR}"
echo "Designs: ${NUM_DESIGNS}"
echo "Cache:   ${CACHE_DIR}"

# Run inside a Slurm step (more reliable GPU binding)
srun --ntasks=1 --gpus-per-task=1 --cpus-per-task="${SLURM_CPUS_PER_TASK}" \
  boltzgen run "${INPUT_FILE}" \
  --output "${JOB_OUT_DIR}" \
  --num_designs "${NUM_DESIGNS}" \
  --cache "${CACHE_DIR}" \
  "$@"

echo "=== NVIDIA-SMI (post-run) ==="
nvidia-smi
